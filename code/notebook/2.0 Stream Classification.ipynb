{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stream Classification\n",
    "---\n",
    "\n",
    "## `NEWeather` dataset\n",
    "\n",
    "**Description:** The National Oceanic and Atmospheric Administration (NOAA),\n",
    "has compiled a database of weather measurements from over 7,000 weather \n",
    "stations worldwide. Records date back to the mid-1900s. Daily measurements\n",
    "include a variety of features (temperature, pressure, wind speed, etc.) as\n",
    "well as a series of indicators for precipitation and other weather-related\n",
    "events. The `NEweather` dataset contains data from this database, specifically\n",
    "from the Offutt Air Force Base in Bellevue, Nebraska ranging for over 50 years\n",
    "(1949-1999).\n",
    "\n",
    "**Features:** 8 Daily weather measurements\n",
    " \n",
    "|       Attribute      | Description |\n",
    "|:--------------------:|:-----------------------------|\n",
    "| `temp`                   | Temperature\n",
    "| `dew_pnt`                | Dew Point\n",
    "| `sea_lvl_press`          | Sea Level Pressure\n",
    "| `visibility`             | Visibility\n",
    "| `avg_wind_spd`           | Average Wind Speed\n",
    "| `max_sustained_wind_spd` | Maximum Sustained Wind Speed\n",
    "| `max_temp`               | Maximum Temperature\n",
    "| `min_temp`               | Minimum Temperature\n",
    "\n",
    "\n",
    "**Class:** `rain` | 0: no rain, 1: rain\n",
    " \n",
    "**Samples:** 18,159\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from river.stream import iter_pandas\n",
    "from river.metrics import Accuracy,BalancedAccuracy,CohenKappa,GeometricMean\n",
    "from river.metrics.base import Metrics\n",
    "from river.utils import Rolling\n",
    "from river.evaluate import progressive_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../datasets/NEweather.csv\")\n",
    "features = data.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we load the data from a csv file with `pandas.read_csv`, and we use the [iter_pandas](https://riverml.xyz/latest/api/stream/iter-pandas/) utility method to iterate over the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = iter_pandas(X=data[features], y=data['rain'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Na√Øve Bayes\n",
    "---\n",
    "[GaussianNB](https://riverml.xyz/0.18.0/api/naive-bayes/GaussianNB/) maintains a Gaussian distribution $G_{cf}$ is maintained for each class $c$ and each feature $f$. Each Gaussian is updated using the amount associated with each feature; the details can be be found in proba.Gaussian. The joint log-likelihood is then obtained by summing the log probabilities of each feature associated with each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "metrics = Metrics(metrics=[Accuracy(),BalancedAccuracy(),GeometricMean(),CohenKappa()])\n",
    "\n",
    "progressive_val_score(dataset=stream,\n",
    "                      model=model,\n",
    "                      metric=metrics,\n",
    "                      print_every=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors\n",
    "---\n",
    "[KNN](https://riverml.xyz/0.18.0/api/neighbors/KNNClassifier/) is a non-parametric classification method that keeps track of the last window_size training samples. The predicted class-label for a given query sample is obtained in two steps:\n",
    "\n",
    "- Find the closest n_neighbors to the query sample in the data window. \n",
    "- Aggregate the class-labels of the n_neighbors to define the predicted class for the query sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river.neighbors import KNNClassifier\n",
    "\n",
    "model = KNNClassifier(n_neighbors=5)\n",
    "metrics = Metrics(metrics=[Accuracy(),BalancedAccuracy(),GeometricMean(),CohenKappa()])\n",
    "stream = iter_pandas(X=data[features], y=data['rain'])\n",
    "\n",
    "progressive_val_score(dataset=stream,\n",
    "                      model=model,\n",
    "                      metric=metrics,\n",
    "                      print_every=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hoeffding Tree\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree-based models are popular due to their interpretability. [Hoeffding Tree](https://riverml.xyz/0.18.0/api/tree/HoeffdingTreeClassifier/)  uses a tree data structure to model the data. When a sample arrives, it traverses the tree until it reaches a leaf node. Internal nodes define the path for a data sample based on the values of its features. Leaf nodes are models that provide predictions for unlabeled-samples and can update their internal state using the labels from labeled samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river.tree import HoeffdingTreeClassifier\n",
    "\n",
    "model = HoeffdingTreeClassifier()\n",
    "metrics = Metrics(metrics=[Accuracy(),BalancedAccuracy(),GeometricMean(),CohenKappa()])\n",
    "stream = iter_pandas(X=data[features], y=data['rain'])\n",
    "\n",
    "progressive_val_score(dataset=stream,\n",
    "                      model=model,\n",
    "                      metric=metrics,\n",
    "                      print_every=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hoeffding Adaptive Tree\n",
    "---\n",
    "The [HAT](https://riverml.xyz/0.18.0/api/tree/HoeffdingAdaptiveTreeClassifier/) model uses [ADWIN](https://riverml.xyz/0.18.0/api/drift/ADWIN/) to detect changes. If change is detected in a given branch, an alternate branch is created and eventually replaces the original branch if it shows better performance on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river.tree import HoeffdingAdaptiveTreeClassifier\n",
    "\n",
    "model = HoeffdingAdaptiveTreeClassifier(seed=42)\n",
    "metrics = Metrics(metrics=[Accuracy(),BalancedAccuracy(),GeometricMean(),CohenKappa()])\n",
    "stream = iter_pandas(X=data[features], y=data['rain'])\n",
    "\n",
    "progressive_val_score(dataset=stream, \n",
    "                      model=model, \n",
    "                      metric=metrics, \n",
    "                      print_every=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaptiveRandomForest\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "The 3 most important aspects of [ARF](https://riverml.xyz/0.18.0/api/forest/ARFClassifier/) are:\n",
    "- inducing diversity through re-sampling\n",
    "- inducing diversity through randomly selecting subsets of features for node splits\n",
    "- drift detectors per base tree, which cause selective resets in response to drifts\n",
    "\n",
    "It also allows training background trees, which start training if a warning is detected and replace the active tree if the warning escalates to a drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river.forest import ARFClassifier\n",
    "\n",
    "model = ARFClassifier(n_models=10)\n",
    "metrics = Metrics(metrics=[Accuracy(),BalancedAccuracy(),GeometricMean(),CohenKappa()])\n",
    "stream = iter_pandas(X=data[features], y=data['rain'])\n",
    "\n",
    "progressive_val_score(dataset=stream,\n",
    "                      model=model,\n",
    "                      metric=metrics,\n",
    "                      print_every=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StreamingRandomPatches\n",
    "---\n",
    "[SRP](https://riverml.xyz/0.18.0/api/ensemble/SRPClassifier/) is an ensemble method that simulates bagging or random subspaces. The default algorithm uses both bagging and random subspaces, namely Random Patches. The default base estimator is a Hoeffding Tree, but other base estimators can be used (differently from random forest variations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river.ensemble import SRPClassifier\n",
    "from river.tree import HoeffdingTreeClassifier\n",
    "\n",
    "model = SRPClassifier(model=HoeffdingTreeClassifier(),\n",
    "                      n_models=10,\n",
    "                      seed=42)\n",
    "metrics = Metrics(metrics=[Accuracy(),BalancedAccuracy(),GeometricMean(),CohenKappa()])\n",
    "stream = iter_pandas(X=data[features], y=data['rain'])\n",
    "\n",
    "progressive_val_score(dataset=stream, \n",
    "                      model=model, \n",
    "                      metric=metrics, \n",
    "                      print_every=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept Drift Impact\n",
    "\n",
    "Concept drift can negatively impact learning methods if not properly handled. Multiple real-world applications suffer **model degradation** as the models can not adapt to changes in the data.\n",
    "\n",
    "---\n",
    "## `AGRAWAL` dataset\n",
    "\n",
    "We will load the data from a csv file. The data was generated using the `AGRAWAL` data generator with 3 **gradual drifts** at the 5k, 10k, and 15k marks. It contains 9 features, 6 numeric and 3 categorical.\n",
    "\n",
    "There are 10 functions for generating binary class labels from the features. These functions determine whether a **loan** should be approved.\n",
    "\n",
    "| Feature    | Description            | Values                                                                |\n",
    "|------------|------------------------|-----------------------------------------------------------------------|\n",
    "| `salary`     | salary                 | uniformly distributed from 20k to 150k                                |\n",
    "| `commission` | commission             | if (salary <   75k) then 0 else uniformly distributed from 10k to 75k |\n",
    "| `age`        | age                    | uniformly distributed from 20 to 80                                   |\n",
    "| `elevel`     | education level        | uniformly chosen from 0 to 4                                          |\n",
    "| `car`        | car maker              | uniformly chosen from 1 to 20                                         |\n",
    "| `zipcode`    | zip code of the town   | uniformly chosen from 0 to 8                                          |\n",
    "| `hvalue`     | value of the house     | uniformly distributed from 50k x zipcode to 100k x zipcode            |\n",
    "| `hyears`     | years house owned      | uniformly distributed from 1 to 30                                    |\n",
    "| `loan`       | total loan amount      | uniformly distributed from 0 to 500k                                  |\n",
    "\n",
    "**Class:** `y` | 0: no loan, 1: loan\n",
    " \n",
    "**Samples:** 20,000\n",
    "\n",
    "`elevel`, `car`, and `zipcode` are categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../datasets/agr_a_20k.csv\")\n",
    "features = data.columns[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Na√Øve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from river.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "metrics = Rolling(Metrics(metrics=[Accuracy(),BalancedAccuracy(),GeometricMean(),CohenKappa()]),window_size=500)\n",
    "stream = iter_pandas(X=data[features], y=data['class'])\n",
    "\n",
    "progressive_val_score(dataset=stream,\n",
    "                      model=model,\n",
    "                      metric=metrics,\n",
    "                      print_every=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hoeffding Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from river.tree import HoeffdingTreeClassifier\n",
    "\n",
    "model = HoeffdingTreeClassifier(nominal_attributes=['elevel', 'car', 'zipcode'])\n",
    "metrics = Rolling(Metrics(metrics=[Accuracy(),BalancedAccuracy(),GeometricMean(),CohenKappa()]),window_size=500)\n",
    "stream = iter_pandas(X=data[features], y=data['class'])\n",
    "\n",
    "progressive_val_score(dataset=stream,\n",
    "                      model=model,\n",
    "                      metric=metrics,\n",
    "                      print_every=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hoeffding Adaptive Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from river.tree import HoeffdingAdaptiveTreeClassifier\n",
    "\n",
    "model = HoeffdingAdaptiveTreeClassifier(nominal_attributes=['elevel', 'car', 'zipcode'], seed=42)\n",
    "metrics = Rolling(Metrics(metrics=[Accuracy(),BalancedAccuracy(),GeometricMean(),CohenKappa()]),window_size=500)\n",
    "stream = iter_pandas(X=data[features], y=data['class'])\n",
    "\n",
    "progressive_val_score(dataset=stream, \n",
    "                      model=model, \n",
    "                      metric=metrics, \n",
    "                      print_every=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaptiveRandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from river.forest import ARFClassifier\n",
    "\n",
    "model = ARFClassifier(n_models=10,nominal_attributes=['elevel', 'car', 'zipcode'])\n",
    "metrics = Rolling(Metrics(metrics=[Accuracy(),BalancedAccuracy(),GeometricMean(),CohenKappa()]),window_size=500)\n",
    "stream = iter_pandas(X=data[features], y=data['class'])\n",
    "\n",
    "progressive_val_score(dataset=stream,\n",
    "                      model=model,\n",
    "                      metric=metrics,\n",
    "                      print_every=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StreamingRandomPatches\n",
    "---\n",
    "We set the drift and warning detection options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from river.ensemble import SRPClassifier\n",
    "from river.tree import HoeffdingTreeClassifier\n",
    "from river.drift import ADWIN\n",
    "\n",
    "model = SRPClassifier(model=HoeffdingTreeClassifier(nominal_attributes=['elevel', 'car', 'zipcode']),\n",
    "                      n_models=10,\n",
    "                      drift_detector=ADWIN(delta=0.001),\n",
    "                      warning_detector=ADWIN(delta=0.01),\n",
    "                      seed=42)\n",
    "\n",
    "metrics = Rolling(Metrics(metrics=[Accuracy(),BalancedAccuracy(),GeometricMean(),CohenKappa()]),window_size=500)\n",
    "stream = iter_pandas(X=data[features], y=data['class'])\n",
    "\n",
    "progressive_val_score(dataset=stream, \n",
    "                      model=model, \n",
    "                      metric=metrics, \n",
    "                      print_every=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
